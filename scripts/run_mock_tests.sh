#!/bin/bash
# scripts/run_mock_tests.sh
# åŸ·è¡Œæ¨¡æ“¬æ¸¬è©¦çš„å®Œæ•´è…³æœ¬

echo "ğŸ§ª LinkedIn çˆ¬èŸ²æ¨¡æ“¬æ¸¬è©¦åŸ·è¡Œè…³æœ¬"
echo "=================================="

# æª¢æŸ¥ç’°å¢ƒ
check_environment() {
    echo "ğŸ” æª¢æŸ¥æ¸¬è©¦ç’°å¢ƒ..."
    
    # æª¢æŸ¥ Python ç’°å¢ƒ
    if ! command -v python3 &> /dev/null; then
        echo "âŒ Python3 æœªå®‰è£"
        exit 1
    fi
    
    # æª¢æŸ¥å¿…è¦å¥—ä»¶
    python3 -c "import requests, bs4, pymongo, psycopg2" 2>/dev/null
    if [ $? -ne 0 ]; then
        echo "âš ï¸  ç¼ºå°‘å¿…è¦ Python å¥—ä»¶ï¼Œæ­£åœ¨å®‰è£..."
        pip install requests beautifulsoup4 pymongo psycopg2-binary lxml
    fi
    
    # æª¢æŸ¥ Docker ç’°å¢ƒ
    if ! docker compose ps | grep -q "Up"; then
        echo "âš ï¸  æœ¬åœ° Docker ç’°å¢ƒæœªé‹è¡Œ"
        echo "è«‹åŸ·è¡Œ: make start"
        read -p "æ˜¯å¦ç¾åœ¨å•Ÿå‹•ï¼Ÿ(y/n): " -n 1 -r
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            make start
            echo "â³ ç­‰å¾…æœå‹™å•Ÿå‹•..."
            sleep 30
        else
            echo "âŒ æ¸¬è©¦éœ€è¦æœ¬åœ°ç’°å¢ƒé‹è¡Œ"
            exit 1
        fi
    fi
    
    echo "âœ… ç’°å¢ƒæª¢æŸ¥é€šé"
}

# éƒ¨ç½²æ¸¬è©¦æª”æ¡ˆ
deploy_test_files() {
    echo "ğŸ“ éƒ¨ç½²æ¸¬è©¦æª”æ¡ˆ..."
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if [ ! -f "src/scrapers/mock_linkedin_scraper.py" ]; then
        echo "âŒ ç¼ºå°‘æ¨¡æ“¬çˆ¬èŸ²æª”æ¡ˆ"
        echo "è«‹ç¢ºä¿å·²ç¶“å»ºç«‹ src/scrapers/mock_linkedin_scraper.py"
        exit 1
    fi
    
    if [ ! -f "dags/scrapers/linkedin_mock_scraper_dag.py" ]; then
        echo "âŒ ç¼ºå°‘æ¨¡æ“¬æ¸¬è©¦ DAG"
        echo "è«‹ç¢ºä¿å·²ç¶“å»ºç«‹ dags/scrapers/linkedin_mock_scraper_dag.py"
        exit 1
    fi
    
    echo "âœ… æ¸¬è©¦æª”æ¡ˆå·²å°±ä½"
}

# æª¢æŸ¥ Airflow DAG
check_airflow_dag() {
    echo "ğŸŒŠ æª¢æŸ¥ Airflow DAG ç‹€æ…‹..."
    
    # ç­‰å¾… Airflow å®Œå…¨å•Ÿå‹•
    echo "â³ ç­‰å¾… Airflow å•Ÿå‹•..."
    for i in {1..12}; do
        if curl -f http://localhost:8080/health &>/dev/null; then
            echo "âœ… Airflow å·²å°±ç·’"
            break
        fi
        echo "   ç­‰å¾…ä¸­... ($i/12)"
        sleep 10
    done
    
    # æª¢æŸ¥ DAG æ˜¯å¦å‡ºç¾
    echo "ğŸ” æª¢æŸ¥æ¸¬è©¦ DAG æ˜¯å¦è¼‰å…¥..."
    
    # çµ¦ Airflow ä¸€äº›æ™‚é–“ä¾†è¼‰å…¥ DAG
    sleep 10
    
    echo "ğŸ’¡ è«‹æ‰‹å‹•ç¢ºèª DAG ç‹€æ…‹:"
    echo "   1. å‰å¾€ http://localhost:8080"
    echo "   2. ç™»å…¥ (admin/admin123)"
    echo "   3. æŸ¥æ‰¾ 'linkedin_mock_scraper_test' DAG"
    echo "   4. ç¢ºèª DAG æ²’æœ‰éŒ¯èª¤ (æ²’æœ‰ç´…è‰²éŒ¯èª¤æ¨™è¨˜)"
    
    read -p "ç¢ºèª DAG æ­£å¸¸è¼‰å…¥å¾ŒæŒ‰ Enter ç¹¼çºŒ..."
}

# åŸ·è¡Œæ¨¡æ“¬æ¸¬è©¦
run_mock_test() {
    echo "ğŸš€ åŸ·è¡Œæ¨¡æ“¬æ¸¬è©¦..."
    
    echo "è«‹åœ¨ Airflow UI ä¸­æ‰‹å‹•è§¸ç™¼æ¸¬è©¦:"
    echo "1. å‰å¾€ http://localhost:8080"
    echo "2. æ‰¾åˆ° 'linkedin_mock_scraper_test' DAG"
    echo "3. é»æ“Š DAG é€²å…¥è©³ç´°é é¢"
    echo "4. é»æ“Šå³ä¸Šè§’çš„ 'Trigger DAG' æŒ‰éˆ•"
    echo "5. è§€å¯Ÿæ‰€æœ‰ Task çš„åŸ·è¡Œç‹€æ³"
    
    echo ""
    echo "ğŸ“Š é æœŸåŸ·è¡Œæ™‚é–“: 2-3 åˆ†é˜"
    echo "ğŸ“‹ é æœŸçµæœ:"
    echo "   - 7 å€‹ Task å…¨éƒ¨æˆåŠŸ (ç¶ è‰²)"
    echo "   - ç”Ÿæˆç´„ 15 ç­†æ¨¡æ“¬è·ç¼ºè³‡æ–™"
    echo "   - è³‡æ–™åŒæ™‚å„²å­˜åˆ° MongoDB å’Œ PostgreSQL"
    
    read -p "æ¸¬è©¦åŸ·è¡Œå®Œæˆå¾ŒæŒ‰ Enter ç¹¼çºŒ..."
}

# é©—è­‰æ¸¬è©¦çµæœ
validate_results() {
    echo "ğŸ” é©—è­‰æ¸¬è©¦çµæœ..."
    
    if [ -f "scripts/validate_mock_test_results.py" ]; then
        echo "åŸ·è¡Œè‡ªå‹•é©—è­‰è…³æœ¬..."
        python3 scripts/validate_mock_test_results.py
        
        if [ $? -eq 0 ]; then
            echo "ğŸ‰ è‡ªå‹•é©—è­‰é€šéï¼"
        else
            echo "âš ï¸  è‡ªå‹•é©—è­‰ç™¼ç¾å•é¡Œï¼Œè«‹æª¢æŸ¥è¼¸å‡º"
        fi
    else
        echo "âš ï¸  è‡ªå‹•é©—è­‰è…³æœ¬ä¸å­˜åœ¨ï¼Œè«‹æ‰‹å‹•æª¢æŸ¥"
        manual_verification
    fi
}

# æ‰‹å‹•é©—è­‰æŒ‡å¼•
manual_verification() {
    echo "ğŸ“‹ æ‰‹å‹•é©—è­‰æ­¥é©Ÿ:"
    echo ""
    echo "1. æª¢æŸ¥ MongoDB Atlas:"
    echo "   - ç™»å…¥ MongoDB Atlas"
    echo "   - é€²å…¥ job_market_data è³‡æ–™åº«"
    echo "   - æŸ¥çœ‹ raw_jobs_data é›†åˆ"
    echo "   - ç¢ºèªæœ‰æ–°çš„æ–‡æª”ï¼Œä¸” metadata.is_mock_data = true"
    echo ""
    echo "2. æª¢æŸ¥ Supabase PostgreSQL:"
    echo "   - ç™»å…¥ Supabase Dashboard"
    echo "   - é€²å…¥ SQL Editor"
    echo "   - åŸ·è¡Œ: SELECT COUNT(*) FROM raw_staging.linkedin_jobs_raw WHERE 'mock_data' = ANY(data_quality_flags);"
    echo "   - ç¢ºèªæœ‰æ–°çš„è¨˜éŒ„"
    echo ""
    echo "3. æª¢æŸ¥ Airflow æ—¥èªŒ:"
    echo "   - åœ¨ Airflow UI ä¸­æŸ¥çœ‹æ¯å€‹ Task çš„æ—¥èªŒ"
    echo "   - ç¢ºèªæ²’æœ‰éŒ¯èª¤è¨Šæ¯"
    echo "   - æŸ¥çœ‹æœ€çµ‚çš„æ¸¬è©¦è©•ä¼°çµæœ"
}

# æ¸…ç†æ¸¬è©¦è³‡æ–™
cleanup_test_data() {
    echo "ğŸ§¹ æ¸…ç†æ¸¬è©¦è³‡æ–™..."
    
    read -p "æ˜¯å¦è¦æ¸…ç†æ¨¡æ“¬æ¸¬è©¦è³‡æ–™ï¼Ÿ(y/n): " -n 1 -r
    echo
    
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "æ­£åœ¨æ¸…ç†æ¨¡æ“¬è³‡æ–™..."
        
        # æ¸…ç† MongoDB æ¨¡æ“¬è³‡æ–™
        python3 -c "
import os
from pymongo import MongoClient
from pymongo.server_api import ServerApi
from dotenv import load_dotenv

load_dotenv()

try:
    mongodb_url = os.getenv('MONGODB_ATLAS_URL')
    if mongodb_url:
        client = MongoClient(mongodb_url, server_api=ServerApi('1'))
        db = client[os.getenv('MONGODB_ATLAS_DB_NAME', 'job_market_data')]
        result = db['raw_jobs_data'].delete_many({'metadata.is_mock_data': True})
        print(f'MongoDB: åˆªé™¤äº† {result.deleted_count} ç­†æ¨¡æ“¬è³‡æ–™')
        client.close()
except Exception as e:
    print(f'MongoDB æ¸…ç†å¤±æ•—: {e}')
"
        
        # æ¸…ç† PostgreSQL æ¨¡æ“¬è³‡æ–™
        python3 -c "
import os
import psycopg2
from dotenv import load_dotenv

load_dotenv()

try:
    supabase_url = os.getenv('SUPABASE_DB_URL')
    if supabase_url:
        conn = psycopg2.connect(supabase_url)
        cur = conn.cursor()
        cur.execute(\"DELETE FROM raw_staging.linkedin_jobs_raw WHERE 'mock_data' = ANY(data_quality_flags)\")
        deleted_count = cur.rowcount
        conn.commit()
        cur.close()
        conn.close()
        print(f'PostgreSQL: åˆªé™¤äº† {deleted_count} ç­†æ¨¡æ“¬è³‡æ–™')
except Exception as e:
    print(f'PostgreSQL æ¸…ç†å¤±æ•—: {e}')
"
        
        echo "âœ… æ¨¡æ“¬è³‡æ–™æ¸…ç†å®Œæˆ"
    else
        echo "ä¿ç•™æ¨¡æ“¬è³‡æ–™"
    fi
}

# ä¸»åŸ·è¡Œæµç¨‹
main() {
    echo "é–‹å§‹åŸ·è¡Œæ¨¡æ“¬æ¸¬è©¦..."
    echo ""
    
    check_environment
    echo ""
    
    deploy_test_files
    echo ""
    
    check_airflow_dag
    echo ""
    
    run_mock_test
    echo ""
    
    validate_results
    echo ""
    
    cleanup_test_data
    echo ""
    
    echo "ğŸ‰ æ¨¡æ“¬æ¸¬è©¦æµç¨‹å®Œæˆï¼"
    echo ""
    echo "ğŸ“‹ ä¸‹ä¸€æ­¥å»ºè­°ï¼š"
    if [ -f "/tmp/test_success" ]; then
        echo "âœ… æ¸¬è©¦æˆåŠŸ - å¯ä»¥é€²è¡ŒçœŸå¯¦çˆ¬èŸ²æ¸¬è©¦"
        echo "   1. ä¿®æ”¹åŸå§‹ LinkedIn DAG ä½¿ç”¨çœŸå¯¦çˆ¬èŸ²"
        echo "   2. è¨­å®šå°è¦æ¨¡æ¸¬è©¦ (target_jobs: 5)"
        echo "   3. åŸ·è¡ŒçœŸå¯¦çˆ¬èŸ²æ¸¬è©¦"
    else
        echo "âš ï¸  éœ€è¦è§£æ±ºæ¸¬è©¦ä¸­ç™¼ç¾çš„å•é¡Œ"
        echo "   1. æª¢æŸ¥éŒ¯èª¤æ—¥èªŒ"
        echo "   2. ä¿®å¾©å•é¡Œå¾Œé‡æ–°æ¸¬è©¦"
        echo "   3. ç¢ºä¿æ‰€æœ‰ Task éƒ½èƒ½æˆåŠŸåŸ·è¡Œ"
    fi
}

# å¿«é€Ÿæ¸¬è©¦é¸é …
quick_test() {
    echo "âš¡ å¿«é€Ÿæ¸¬è©¦æ¨¡å¼"
    echo "å‡è¨­ç’°å¢ƒå·²ç¶“æº–å‚™å°±ç·’ï¼Œç›´æ¥åŸ·è¡Œæ ¸å¿ƒæ¸¬è©¦"
    
    echo "ğŸ” æª¢æŸ¥ Airflow ç‹€æ…‹..."
    if ! curl -f http://localhost:8080/health &>/dev/null; then
        echo "âŒ Airflow æœªé‹è¡Œï¼Œè«‹å…ˆåŸ·è¡Œå®Œæ•´æ¸¬è©¦"
        exit 1
    fi
    
    echo "ğŸš€ è«‹æ‰‹å‹•è§¸ç™¼ linkedin_mock_scraper_test DAG"
    echo "â³ ç­‰å¾…åŸ·è¡Œå®Œæˆ..."
    
    read -p "åŸ·è¡Œå®Œæˆå¾ŒæŒ‰ Enter é©—è­‰çµæœ..."
    
    validate_results
}

# è§£æå‘½ä»¤è¡Œåƒæ•¸
case "${1:-}" in
    "quick")
        quick_test
        ;;
    "validate")
        validate_results
        ;;
    "cleanup")
        cleanup_test_data
        ;;
    "check")
        check_environment
        check_airflow_dag
        ;;
    *)
        main
        ;;
esac