import psycopg2
import json
from datetime import datetime, date
import os
from dotenv import load_dotenv

load_dotenv()

def migrate_test_data():
    local_conn = None
    supabase_conn = None
    
    try:
        # é€£æ¥æœ¬åœ°è³‡æ–™åº«
        local_conn = psycopg2.connect(
            host="localhost",
            port=5433,
            database="job_data_warehouse", 
            user="dwh_user",
            password="dwh_password"
        )
        
        # é€£æ¥ Supabase
        supabase_conn = psycopg2.connect(os.getenv('SUPABASE_DB_URL'))
        
        local_cur = local_conn.cursor()
        supabase_cur = supabase_conn.cursor()
        
        print("ğŸ”„ é–‹å§‹é·ç§»æ¸¬è©¦è³‡æ–™...")
        
        # é·ç§»é †åºï¼šç¶­åº¦è¡¨ â†’ äº‹å¯¦è¡¨ â†’ æ©‹æ¥è¡¨
        tables_to_migrate = [
            ('dwh.dim_companies', 'company_key'),
            ('dwh.dim_locations', 'location_key'), 
            ('dwh.dim_job_roles', 'role_key'),
            ('dwh.dim_skills', 'skill_key'),
            ('dwh.dim_dates', 'date_key'),
            ('dwh.fact_jobs', 'job_key'),
            ('dwh.bridge_job_skills', None)  # è¤‡åˆä¸»éµ
        ]
        
        for table_name, primary_key in tables_to_migrate:
            print(f"ğŸ“¦ é·ç§» {table_name}...")
            
            # å¾æœ¬åœ°è®€å–è³‡æ–™
            local_cur.execute(f"SELECT * FROM {table_name}")
            rows = local_cur.fetchall()
            
            if not rows:
                print(f"  âš ï¸  {table_name} æ²’æœ‰è³‡æ–™")
                continue
            
            # å–å¾—æ¬„ä½åç¨±
            local_cur.execute(f"""
                SELECT column_name 
                FROM information_schema.columns 
                WHERE table_schema = '{table_name.split('.')[0]}' 
                AND table_name = '{table_name.split('.')[1]}'
                ORDER BY ordinal_position
            """)
            columns = [row[0] for row in local_cur.fetchall()]
            
            # æ’å…¥åˆ° Supabase
            placeholders = ', '.join(['%s'] * len(columns))
            columns_str = ', '.join(columns)
            
            insert_sql = f"""
                INSERT INTO {table_name} ({columns_str}) 
                VALUES ({placeholders})
                ON CONFLICT DO NOTHING
            """
            
            supabase_cur.executemany(insert_sql, rows)
            print(f"  âœ… {table_name}: {len(rows)} ç­†è³‡æ–™")
        
        supabase_conn.commit()
        print("\nğŸ‰ æ¸¬è©¦è³‡æ–™é·ç§»å®Œæˆï¼")
        
        # é©—è­‰è³‡æ–™
        print("\nğŸ“Š é©—è­‰é·ç§»çµæœï¼š")
        for table_name, _ in tables_to_migrate:
            supabase_cur.execute(f"SELECT COUNT(*) FROM {table_name}")
            count = supabase_cur.fetchone()[0]
            print(f"  - {table_name}: {count} ç­†")
        
        return True
        
    except Exception as e:
        print(f"âŒ è³‡æ–™é·ç§»å¤±æ•—: {str(e)}")
        return False
        
    finally:
        if local_conn:
            local_conn.close()
        if supabase_conn:
            supabase_conn.close()

if __name__ == "__main__":
    migrate_test_data()