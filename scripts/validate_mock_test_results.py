# scripts/validate_mock_test_results.py
# é©—è­‰æ¨¡æ“¬æ¸¬è©¦çµæœçš„è…³æœ¬

import psycopg2
from pymongo import MongoClient
from pymongo.server_api import ServerApi
import os
from datetime import datetime, timedelta
from dotenv import load_dotenv

load_dotenv()

def validate_mock_test_results():
    """é©—è­‰æ¨¡æ“¬æ¸¬è©¦çš„å®Œæ•´çµæœ"""
    
    print("ğŸ§ª é©—è­‰æ¨¡æ“¬æ¸¬è©¦çµæœ")
    print("=" * 50)
    
    validation_results = {
        'mongodb_validation': False,
        'postgresql_validation': False,
        'data_consistency': False,
        'overall_success': False
    }
    
    # 1. é©—è­‰ MongoDB Atlas ä¸­çš„æ¨¡æ“¬è³‡æ–™
    print("\nğŸ“Š 1. æª¢æŸ¥ MongoDB Atlas...")
    try:
        mongodb_url = os.getenv('MONGODB_ATLAS_URL')
        if not mongodb_url:
            print("   âš ï¸  MONGODB_ATLAS_URL æœªè¨­å®šï¼Œè·³é MongoDB é©—è­‰")
        else:
            client = MongoClient(mongodb_url, server_api=ServerApi('1'))
            db = client[os.getenv('MONGODB_ATLAS_DB_NAME', 'job_market_data')]
            
            # æŸ¥æ‰¾æœ€è¿‘çš„æ¨¡æ“¬è³‡æ–™
            recent_cutoff = datetime.now() - timedelta(hours=1)
            mock_jobs = db['raw_jobs_data'].find({
                'metadata.is_mock_data': True,
                'metadata.scraped_at': {'$gte': recent_cutoff}
            })
            
            mock_job_list = list(mock_jobs)
            mock_count = len(mock_job_list)
            
            if mock_count > 0:
                print(f"   âœ… æ‰¾åˆ° {mock_count} ç­†æ¨¡æ“¬è³‡æ–™")
                
                # æª¢æŸ¥è³‡æ–™çµæ§‹
                sample_job = mock_job_list[0]
                required_fields = ['source', 'job_data', 'metadata', 'data_quality']
                
                missing_fields = [field for field in required_fields if field not in sample_job]
                if not missing_fields:
                    print("   âœ… è³‡æ–™çµæ§‹æ­£ç¢º")
                    validation_results['mongodb_validation'] = True
                else:
                    print(f"   âŒ ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_fields}")
                
                # æª¢æŸ¥æ¨¡æ“¬è³‡æ–™æ¨™è¨˜
                mock_marked = all(job.get('metadata', {}).get('is_mock_data', False) for job in mock_job_list)
                if mock_marked:
                    print("   âœ… æ‰€æœ‰è³‡æ–™éƒ½æ­£ç¢ºæ¨™è¨˜ç‚ºæ¨¡æ“¬è³‡æ–™")
                else:
                    print("   âš ï¸  éƒ¨åˆ†è³‡æ–™æœªæ­£ç¢ºæ¨™è¨˜ç‚ºæ¨¡æ“¬è³‡æ–™")
                
            else:
                print("   âŒ æœªæ‰¾åˆ°æœ€è¿‘çš„æ¨¡æ“¬è³‡æ–™")
            
            client.close()
    
    except Exception as e:
        print(f"   âŒ MongoDB é©—è­‰å¤±æ•—: {str(e)}")
    
    # 2. é©—è­‰ PostgreSQL Supabase ä¸­çš„æ¨¡æ“¬è³‡æ–™
    print("\nğŸ“Š 2. æª¢æŸ¥ PostgreSQL Supabase...")
    try:
        supabase_url = os.getenv('SUPABASE_DB_URL')
        if not supabase_url:
            print("   âš ï¸  SUPABASE_DB_URL æœªè¨­å®šï¼Œè·³é PostgreSQL é©—è­‰")
        else:
            conn = psycopg2.connect(supabase_url)
            cur = conn.cursor()
            
            # æŸ¥æ‰¾æœ€è¿‘çš„æ¨¡æ“¬è³‡æ–™
            recent_cutoff = datetime.now() - timedelta(hours=1)
            cur.execute("""
                SELECT COUNT(*), batch_id, scraped_at 
                FROM raw_staging.linkedin_jobs_raw 
                WHERE 'mock_data' = ANY(data_quality_flags) 
                AND scraped_at >= %s
                GROUP BY batch_id, scraped_at
                ORDER BY scraped_at DESC
                LIMIT 5
            """, (recent_cutoff,))
            
            results = cur.fetchall()
            
            if results:
                total_mock_jobs = sum(row[0] for row in results)
                latest_batch = results[0]
                
                print(f"   âœ… æ‰¾åˆ° {total_mock_jobs} ç­†æ¨¡æ“¬è³‡æ–™")
                print(f"   ğŸ“‹ æœ€æ–°æ‰¹æ¬¡: {latest_batch[1]} ({latest_batch[0]} ç­†)")
                
                # æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§
                cur.execute("""
                    SELECT 
                        COUNT(*) as total,
                        COUNT(job_title) as has_title,
                        COUNT(company_name) as has_company,
                        COUNT(location_raw) as has_location,
                        COUNT(job_description) as has_description
                    FROM raw_staging.linkedin_jobs_raw 
                    WHERE 'mock_data' = ANY(data_quality_flags)
                    AND scraped_at >= %s
                """, (recent_cutoff,))
                
                completeness = cur.fetchone()
                if completeness:
                    total = completeness[0]
                    required_complete = completeness[1] == completeness[2] == completeness[3] == total
                    
                    if required_complete:
                        print("   âœ… å¿…è¦æ¬„ä½å®Œæ•´æ€§æª¢æŸ¥é€šé")
                        validation_results['postgresql_validation'] = True
                    else:
                        print("   âŒ éƒ¨åˆ†è³‡æ–™ç¼ºå°‘å¿…è¦æ¬„ä½")
                        print(f"      æ¨™é¡Œ: {completeness[1]}/{total}")
                        print(f"      å…¬å¸: {completeness[2]}/{total}")
                        print(f"      åœ°é»: {completeness[3]}/{total}")
                
            else:
                print("   âŒ æœªæ‰¾åˆ°æœ€è¿‘çš„æ¨¡æ“¬è³‡æ–™")
            
            conn.close()
    
    except Exception as e:
        print(f"   âŒ PostgreSQL é©—è­‰å¤±æ•—: {str(e)}")
    
    # 3. æª¢æŸ¥è³‡æ–™ä¸€è‡´æ€§
    print("\nğŸ“Š 3. æª¢æŸ¥è³‡æ–™ä¸€è‡´æ€§...")
    if validation_results['mongodb_validation'] and validation_results['postgresql_validation']:
        try:
            # æ¯”è¼ƒå…©å€‹è³‡æ–™åº«ä¸­çš„è³‡æ–™æ•¸é‡
            # é€™è£¡å¯ä»¥åŠ å…¥æ›´è©³ç´°çš„ä¸€è‡´æ€§æª¢æŸ¥
            print("   âœ… å…©å€‹è³‡æ–™åº«éƒ½æœ‰æ¨¡æ“¬è³‡æ–™")
            validation_results['data_consistency'] = True
        except Exception as e:
            print(f"   âŒ è³‡æ–™ä¸€è‡´æ€§æª¢æŸ¥å¤±æ•—: {str(e)}")
    else:
        print("   âš ï¸  ç„¡æ³•é€²è¡Œä¸€è‡´æ€§æª¢æŸ¥ï¼ˆéƒ¨åˆ†è³‡æ–™åº«é©—è­‰å¤±æ•—ï¼‰")
    
    # 4. æ•´é«”è©•ä¼°
    print("\nğŸ“Š 4. æ•´é«”è©•ä¼°...")
    
    success_count = sum(validation_results.values())
    total_checks = len(validation_results) - 1  # æ’é™¤ overall_success
    
    if success_count >= total_checks - 1:  # å…è¨±ä¸€å€‹æª¢æŸ¥å¤±æ•—
        validation_results['overall_success'] = True
        print("   ğŸ‰ æ•´é«”æ¸¬è©¦æˆåŠŸï¼æ¨¡æ“¬è³‡æ–™æµç¨‹é‹ä½œæ­£å¸¸")
    else:
        print("   âŒ æ¸¬è©¦éƒ¨åˆ†å¤±æ•—ï¼Œéœ€è¦æª¢æŸ¥å•é¡Œ")
    
    # 5. ç¸½çµå ±å‘Š
    print("\n" + "=" * 50)
    print("ğŸ“‹ æ¸¬è©¦çµæœç¸½çµ:")
    print(f"   MongoDB é©—è­‰: {'âœ… é€šé' if validation_results['mongodb_validation'] else 'âŒ å¤±æ•—'}")
    print(f"   PostgreSQL é©—è­‰: {'âœ… é€šé' if validation_results['postgresql_validation'] else 'âŒ å¤±æ•—'}")
    print(f"   è³‡æ–™ä¸€è‡´æ€§: {'âœ… é€šé' if validation_results['data_consistency'] else 'âŒ å¤±æ•—'}")
    print(f"   æ•´é«”çµæœ: {'ğŸ‰ æˆåŠŸ' if validation_results['overall_success'] else 'âŒ å¤±æ•—'}")
    
    if validation_results['overall_success']:
        print("\nğŸš€ ä¸‹ä¸€æ­¥å»ºè­°:")
        print("   1. æ¨¡æ“¬æ¸¬è©¦é€šéï¼Œå¯ä»¥é–‹å§‹çœŸå¯¦çˆ¬èŸ²æ¸¬è©¦")
        print("   2. ä¿®æ”¹ LinkedIn Scraper DAG ä½¿ç”¨çœŸå¯¦çˆ¬èŸ²")
        print("   3. é€²è¡Œå°è¦æ¨¡çœŸå¯¦è³‡æ–™æ¸¬è©¦ (5-10 å€‹è·ç¼º)")
    else:
        print("\nğŸ”§ ä¿®å¾©å»ºè­°:")
        print("   1. æª¢æŸ¥ Airflow DAG åŸ·è¡Œæ—¥èªŒ")
        print("   2. ç¢ºèªè³‡æ–™åº«é€£ç·šè¨­å®š")
        print("   3. é‡æ–°åŸ·è¡Œæ¨¡æ“¬æ¸¬è©¦")
    
    return validation_results['overall_success']


def check_recent_airflow_runs():
    """æª¢æŸ¥æœ€è¿‘çš„ Airflow DAG åŸ·è¡Œç‹€æ³"""
    print("\nğŸŒŠ æª¢æŸ¥æœ€è¿‘çš„ Airflow åŸ·è¡Œ...")
    
    # é€™è£¡å¯ä»¥åŠ å…¥æª¢æŸ¥ Airflow åŸ·è¡Œç‹€æ³çš„é‚è¼¯
    # æ¯”å¦‚æª¢æŸ¥ dag_run è¡¨æˆ–ä½¿ç”¨ Airflow API
    
    print("   ğŸ’¡ è«‹æ‰‹å‹•æª¢æŸ¥ Airflow UI:")
    print("   1. å‰å¾€ http://localhost:8080")
    print("   2. æ‰¾åˆ° 'linkedin_mock_scraper_test' DAG")
    print("   3. ç¢ºèªæœ€è¿‘åŸ·è¡Œæ˜¯å¦æˆåŠŸ")
    print("   4. æŸ¥çœ‹æ¯å€‹ Task çš„æ—¥èªŒè¼¸å‡º")


if __name__ == "__main__":
    print("ğŸ§ª é–‹å§‹é©—è­‰æ¨¡æ“¬æ¸¬è©¦çµæœ...")
    print("ç¢ºä¿ä½ å·²ç¶“åŸ·è¡Œäº† linkedin_mock_scraper_test DAG")
    print()
    
    success = validate_mock_test_results()
    
    check_recent_airflow_runs()
    
    if success:
        exit(0)
    else:
        exit(1)