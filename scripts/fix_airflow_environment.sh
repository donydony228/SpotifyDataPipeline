#!/bin/bash
# scripts/fix_airflow_environment.sh
# ä¿®å¾© Airflow ç„¡æ³•è®€å– .env æª”æ¡ˆçš„å•é¡Œ

echo "ğŸ”§ ä¿®å¾© Airflow ç’°å¢ƒè®Šæ•¸å•é¡Œ"
echo "============================="

# æª¢æŸ¥ .env æª”æ¡ˆæ˜¯å¦å­˜åœ¨
if [ ! -f ".env" ]; then
    echo "âŒ .env æª”æ¡ˆä¸å­˜åœ¨æ–¼ç•¶å‰ç›®éŒ„"
    echo "è«‹ç¢ºä¿ .env æª”æ¡ˆå­˜åœ¨ä¸¦åŒ…å«æ­£ç¢ºçš„é›²ç«¯è³‡æ–™åº«é€£ç·šè³‡è¨Š"
    exit 1
fi

echo "âœ… æ‰¾åˆ° .env æª”æ¡ˆ"

# æª¢æŸ¥ .env å…§å®¹
echo "ğŸ” æª¢æŸ¥ .env å…§å®¹..."
required_vars=("SUPABASE_DB_URL" "MONGODB_ATLAS_URL" "MONGODB_ATLAS_DB_NAME")
missing_vars=()

for var in "${required_vars[@]}"; do
    if grep -q "^${var}=" .env; then
        value=$(grep "^${var}=" .env | cut -d'=' -f2-)
        if [ -n "$value" ] && [ "$value" != "[ä½ çš„å¯†ç¢¼]" ] && [ "$value" != "[password]" ]; then
            echo "âœ… $var: å·²è¨­å®š"
        else
            echo "âŒ $var: å€¼ç‚ºç©ºæˆ–æ˜¯ç¯„ä¾‹å€¼"
            missing_vars+=("$var")
        fi
    else
        echo "âŒ $var: æœªæ‰¾åˆ°"
        missing_vars+=("$var")
    fi
done

if [ ${#missing_vars[@]} -gt 0 ]; then
    echo ""
    echo "âš ï¸  ç™¼ç¾ ${#missing_vars[@]} å€‹ç¼ºå°‘æˆ–ç„¡æ•ˆçš„ç’°å¢ƒè®Šæ•¸:"
    for var in "${missing_vars[@]}"; do
        echo "   - $var"
    done
    echo ""
    echo "è«‹ç¢ºä¿é€™äº›è®Šæ•¸åœ¨ .env æª”æ¡ˆä¸­æ­£ç¢ºè¨­å®š"
    read -p "ä¿®æ­£å¾ŒæŒ‰ Enter ç¹¼çºŒï¼Œæˆ–æŒ‰ Ctrl+C å–æ¶ˆ..."
fi

# æ–¹æ³•1: è¤‡è£½ .env åˆ° Airflow å®¹å™¨ä¸­
echo ""
echo "ğŸ”§ æ–¹æ³•1: è¤‡è£½ .env åˆ° Airflow å®¹å™¨..."

if docker compose ps | grep -q "airflow-webserver.*Up"; then
    echo "ğŸ“‹ Airflow å®¹å™¨æ­£åœ¨é‹è¡Œï¼Œè¤‡è£½ .env æª”æ¡ˆ..."
    
    # è¤‡è£½åˆ°å¤šå€‹å¯èƒ½çš„ä½ç½®
    docker compose exec airflow-webserver mkdir -p /opt/airflow || true
    docker compose cp .env airflow-webserver:/opt/airflow/.env
    docker compose cp .env airflow-webserver:/app/.env
    
    echo "âœ… .env æª”æ¡ˆå·²è¤‡è£½åˆ° Airflow å®¹å™¨"
    
    # é©—è­‰è¤‡è£½çµæœ
    echo "ğŸ” é©—è­‰è¤‡è£½çµæœ..."
    docker compose exec airflow-webserver ls -la /opt/airflow/.env || echo "âŒ /opt/airflow/.env ä¸å­˜åœ¨"
    docker compose exec airflow-webserver ls -la /app/.env || echo "âŒ /app/.env ä¸å­˜åœ¨"
else
    echo "âš ï¸  Airflow å®¹å™¨æœªé‹è¡Œï¼Œè·³éå®¹å™¨å…§è¤‡è£½"
fi

# æ–¹æ³•2: æ›´æ–° docker-compose.yml åŠ å…¥ç’°å¢ƒè®Šæ•¸
echo ""
echo "ğŸ”§ æ–¹æ³•2: æ›´æ–° docker-compose.yml..."

# å‚™ä»½åŸå§‹æª”æ¡ˆ
cp docker-compose.yml docker-compose.yml.backup

# æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰ env_file è¨­å®š
if grep -q "env_file:" docker-compose.yml; then
    echo "âœ… docker-compose.yml å·²ç¶“åŒ…å« env_file è¨­å®š"
else
    echo "ğŸ“ æ›´æ–° docker-compose.yml åŠ å…¥ env_file..."
    
    # å»ºç«‹è‡¨æ™‚æª”æ¡ˆ
    temp_file=$(mktemp)
    
    # åœ¨ airflow ç›¸é—œæœå‹™ä¸­åŠ å…¥ env_file
    awk '
    /^  airflow-webserver:|^  airflow-scheduler:/ {
        service_name = $1
        print $0
        in_service = 1
        next
    }
    in_service && /^  [a-zA-Z]/ && !/^    / {
        in_service = 0
    }
    in_service && /^    environment:/ {
        print $0
        print "    env_file:"
        print "      - .env"
        next
    }
    in_service && /^    volumes:/ && !env_added {
        print "    env_file:"
        print "      - .env"
        env_added = 1
    }
    { print $0 }
    ' docker-compose.yml > "$temp_file"
    
    mv "$temp_file" docker-compose.yml
    echo "âœ… docker-compose.yml å·²æ›´æ–°"
fi

# æ–¹æ³•3: å»ºç«‹ç’°å¢ƒè®Šæ•¸è¨­å®šè…³æœ¬
echo ""
echo "ğŸ”§ æ–¹æ³•3: å»ºç«‹ç’°å¢ƒè®Šæ•¸è¨­å®šè…³æœ¬..."

cat > scripts/set_airflow_env.sh << 'EOF'
#!/bin/bash
# ç‚º Airflow è¨­å®šç’°å¢ƒè®Šæ•¸

if [ -f ".env" ]; then
    echo "ğŸ“ è¼‰å…¥ .env æª”æ¡ˆä¸­çš„ç’°å¢ƒè®Šæ•¸..."
    export $(grep -v '^#' .env | xargs)
    
    echo "âœ… ç’°å¢ƒè®Šæ•¸å·²è¨­å®š:"
    echo "   SUPABASE_DB_URL: ${SUPABASE_DB_URL:0:30}***"
    echo "   MONGODB_ATLAS_URL: ${MONGODB_ATLAS_URL:0:30}***"
    echo "   MONGODB_ATLAS_DB_NAME: $MONGODB_ATLAS_DB_NAME"
else
    echo "âŒ .env æª”æ¡ˆä¸å­˜åœ¨"
    exit 1
fi
EOF

chmod +x scripts/set_airflow_env.sh
echo "âœ… ç’°å¢ƒè®Šæ•¸è¨­å®šè…³æœ¬å·²å»ºç«‹: scripts/set_airflow_env.sh"

# æ–¹æ³•4: å»ºç«‹ä¿®å¾©ç‰ˆ DAG
echo ""
echo "ğŸ”§ æ–¹æ³•4: éƒ¨ç½²ä¿®å¾©ç‰ˆ DAG..."

# æª¢æŸ¥ä¿®å¾©ç‰ˆ DAG æ˜¯å¦å­˜åœ¨
if [ -f "dags/scrapers/linkedin_mock_scraper_env_fixed.py" ]; then
    echo "âœ… ç’°å¢ƒè®Šæ•¸ä¿®å¾©ç‰ˆ DAG å·²å­˜åœ¨"
else
    echo "ğŸ“ å»ºç«‹ç’°å¢ƒè®Šæ•¸ä¿®å¾©ç‰ˆ DAG..."
    echo "è«‹å¾ Claude çš„å›æ‡‰ä¸­è¤‡è£½ linkedin_mock_scraper_env_fixed.py åˆ° dags/scrapers/ ç›®éŒ„"
fi

# é‡å•Ÿ Airflow æœå‹™
echo ""
echo "ğŸ”„ é‡å•Ÿ Airflow æœå‹™ä»¥è¼‰å…¥æ–°è¨­å®š..."
read -p "æ˜¯å¦é‡å•Ÿ Airflow æœå‹™ï¼Ÿ(y/n): " -n 1 -r
echo

if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "ğŸ”„ é‡å•Ÿ Airflow æœå‹™..."
    docker compose restart airflow-webserver airflow-scheduler
    
    echo "â³ ç­‰å¾…æœå‹™é‡æ–°å•Ÿå‹•..."
    sleep 30
    
    # æª¢æŸ¥æœå‹™ç‹€æ…‹
    if docker compose ps | grep -q "airflow-webserver.*Up"; then
        echo "âœ… Airflow Webserver å·²é‡å•Ÿ"
    else
        echo "âŒ Airflow Webserver é‡å•Ÿå¤±æ•—"
    fi
    
    if docker compose ps | grep -q "airflow-scheduler.*Up"; then
        echo "âœ… Airflow Scheduler å·²é‡å•Ÿ"
    else
        echo "âŒ Airflow Scheduler é‡å•Ÿå¤±æ•—"
    fi
fi

# æ¸¬è©¦ç’°å¢ƒè®Šæ•¸
echo ""
echo "ğŸ§ª æ¸¬è©¦ç’°å¢ƒè®Šæ•¸è¼‰å…¥..."

if command -v python3 &> /dev/null; then
    python3 -c "
import os
from dotenv import load_dotenv

print('ğŸ” æ¸¬è©¦æœ¬åœ°ç’°å¢ƒè®Šæ•¸è¼‰å…¥...')

# è¼‰å…¥ .env
load_dotenv()

vars_to_check = ['SUPABASE_DB_URL', 'MONGODB_ATLAS_URL', 'MONGODB_ATLAS_DB_NAME']
for var in vars_to_check:
    value = os.getenv(var)
    if value:
        masked = f'{value[:20]}***' if len(value) > 20 else '***'
        print(f'âœ… {var}: {masked}')
    else:
        print(f'âŒ {var}: æœªè¨­å®š')

print('\\nğŸ”— æ¸¬è©¦è³‡æ–™åº«é€£ç·š...')
try:
    import psycopg2
    supabase_url = os.getenv('SUPABASE_DB_URL')
    if supabase_url:
        conn = psycopg2.connect(supabase_url, connect_timeout=10)
        conn.close()
        print('âœ… Supabase é€£ç·šæˆåŠŸ')
    else:
        print('âŒ Supabase URL æœªè¨­å®š')
except Exception as e:
    print(f'âŒ Supabase é€£ç·šå¤±æ•—: {e}')

try:
    from pymongo import MongoClient
    from pymongo.server_api import ServerApi
    mongodb_url = os.getenv('MONGODB_ATLAS_URL')
    if mongodb_url:
        client = MongoClient(mongodb_url, server_api=ServerApi('1'), serverSelectionTimeoutMS=5000)
        client.admin.command('ping')
        client.close()
        print('âœ… MongoDB Atlas é€£ç·šæˆåŠŸ')
    else:
        print('âŒ MongoDB Atlas URL æœªè¨­å®š')
except Exception as e:
    print(f'âŒ MongoDB Atlas é€£ç·šå¤±æ•—: {e}')
"
else
    echo "âš ï¸  Python3 ä¸å¯ç”¨ï¼Œè·³éé€£ç·šæ¸¬è©¦"
fi

echo ""
echo "ğŸ“‹ ä¿®å¾©æ‘˜è¦"
echo "============"
echo "âœ… å·²åŸ·è¡Œçš„ä¿®å¾©æ­¥é©Ÿ:"
echo "   1. æª¢æŸ¥ .env æª”æ¡ˆå…§å®¹"
echo "   2. è¤‡è£½ .env åˆ° Airflow å®¹å™¨ (å¦‚æœé‹è¡Œä¸­)"
echo "   3. æ›´æ–° docker-compose.yml åŠ å…¥ env_file"
echo "   4. å»ºç«‹ç’°å¢ƒè®Šæ•¸è¨­å®šè…³æœ¬"
echo "   5. é‡å•Ÿ Airflow æœå‹™ (å¦‚æœé¸æ“‡)"
echo ""
echo "ğŸš€ ä¸‹ä¸€æ­¥æ¸¬è©¦:"
echo "   1. å‰å¾€ Airflow UI: http://localhost:8080"
echo "   2. æŸ¥æ‰¾ 'linkedin_mock_scraper_env_fixed' DAG"
echo "   3. æ‰‹å‹•è§¸ç™¼åŸ·è¡Œ"
echo "   4. æª¢æŸ¥æ˜¯å¦èƒ½æ­£ç¢ºè®€å–ç’°å¢ƒè®Šæ•¸"
echo ""
echo "ğŸ“ å¦‚æœå•é¡ŒæŒçºŒ:"
echo "   1. æª¢æŸ¥ .env æª”æ¡ˆæ ¼å¼ (ç„¡ç©ºæ ¼ã€ç„¡å¼•è™Ÿ)"
echo "   2. ç¢ºèªé›²ç«¯è³‡æ–™åº« URL æ­£ç¢º"
echo "   3. æŸ¥çœ‹ Airflow å®¹å™¨æ—¥èªŒ: docker compose logs airflow-webserver"