#!/usr/bin/env python3
"""
ğŸµ Supabase è³‡æ–™åº«é€£ç·šç®¡ç†å™¨ - ç°¡åŒ–ç‰ˆæœ¬
ä½¿ç”¨ç´” psycopg2ï¼Œé¿å… SQLAlchemy ç›¸å®¹æ€§å•é¡Œ
"""

import os
import pandas as pd
import psycopg2
from psycopg2.extras import RealDictCursor
import logging
from dotenv import load_dotenv
import warnings
import numpy as np

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

class SupabaseManager:
    """
    Supabase PostgreSQL è³‡æ–™åº«ç®¡ç†å™¨ - ç°¡åŒ–ç‰ˆ
    """
    
    def __init__(self):
        """åˆå§‹åŒ–è³‡æ–™åº«é€£ç·šåƒæ•¸"""
        self.connection_string = os.getenv('SUPABASE_DB_URL')
        
        if not self.connection_string:
            self.db_config = {
                'host': os.getenv('SUPABASE_HOST', 'localhost'),
                'port': os.getenv('SUPABASE_PORT', '5432'),
                'database': os.getenv('SUPABASE_DATABASE', 'postgres'),
                'user': os.getenv('SUPABASE_USER', 'postgres'),
                'password': os.getenv('SUPABASE_PASSWORD', '')
            }
        
        self.connection = None
        self.logger = self._setup_logger()
    
    def _setup_logger(self):
        """è¨­å®šæ—¥èªŒè¨˜éŒ„å™¨"""
        logger = logging.getLogger('SupabaseManager')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def connect(self):
        """å»ºç«‹è³‡æ–™åº«é€£ç·š"""
        try:
            if self.connection_string:
                self.connection = psycopg2.connect(
                    self.connection_string,
                    cursor_factory=RealDictCursor
                )
            else:
                self.connection = psycopg2.connect(
                    **self.db_config,
                    cursor_factory=RealDictCursor
                )
            
            # self.logger.info("âœ… æˆåŠŸé€£æ¥åˆ° Supabase")
            return True
            
        except Exception as e:
            # self.logger.error(f"âŒ é€£æ¥è³‡æ–™åº«å¤±æ•—: {e}")
            return False
    
    def disconnect(self):
        """é—œé–‰è³‡æ–™åº«é€£ç·š"""
        if self.connection:
            self.connection.close()
            self.connection = None
            # self.logger.info("ğŸ”Œ å·²é—œé–‰è³‡æ–™åº«é€£ç·š")
    
    def test_connection(self):
        """æ¸¬è©¦è³‡æ–™åº«é€£ç·š"""
        if not self.connect():
            return False
        
        try:
            with self.connection.cursor() as cursor:
                cursor.execute("SELECT 1 as test")
                result = cursor.fetchone()
                
                if result and result['test'] == 1:
                    # self.logger.info("âœ… è³‡æ–™åº«é€£ç·šæ¸¬è©¦æˆåŠŸ")
                    return True
                else:
                    # self.logger.error("âŒ è³‡æ–™åº«é€£ç·šæ¸¬è©¦å¤±æ•—")
                    return False
                    
        except Exception as e:
            self.logger.error(f"âŒ é€£ç·šæ¸¬è©¦éŒ¯èª¤: {e}")
            return False
        finally:
            self.disconnect()
    
    # def execute_query(self, query, params=None):
    #     """
    #     åŸ·è¡Œ SQL æŸ¥è©¢ä¸¦å›å‚³ DataFrame
    #     """
    #     if not self.connect():
    #         return pd.DataFrame()
        
    #     try:
    #         # æŠ‘åˆ¶ pandas è­¦å‘Š
    #         with warnings.catch_warnings():
    #             warnings.filterwarnings("ignore", message="pandas only supports SQLAlchemy")
    #             df = pd.read_sql_query(query, self.connection, params=params)
                
    #         self.logger.info(f"âœ… æŸ¥è©¢æˆåŠŸï¼Œå›å‚³ {len(df)} ç­†è³‡æ–™")
    #         return df
            
    #     except Exception as e:
    #         self.logger.error(f"âŒ æŸ¥è©¢åŸ·è¡Œå¤±æ•—: {e}")
    #         return pd.DataFrame()
    #     finally:
    #         self.disconnect()
    
    def execute_query(self, query, params=None):
        if not self.connect():
            return pd.DataFrame()
        
        try:
            # print(f"åŸ·è¡Œçš„æŸ¥è©¢: {query}")
            
            # å…ˆç”¨ cursor ç›´æ¥æŸ¥è©¢ï¼Œç¢ºèªåŸå§‹çµæœ
            with self.connection.cursor() as cursor:
                cursor.execute(query, params)
                results = cursor.fetchall()
                columns = [desc[0] for desc in cursor.description]
                
                # print(f"åŸå§‹æŸ¥è©¢çµæœ: {results}")
                # print(f"æ¬„ä½åç¨±: {columns}")
                
                # æ‰‹å‹•å»ºç«‹ DataFrame
                df = pd.DataFrame(results, columns=columns)
            
            # print(f"DataFrame çµæœ: {df}")
            # print(f"è³‡æ–™é¡å‹: {df.dtypes}")
            
            # self.logger.info(f"âœ… æŸ¥è©¢æˆåŠŸï¼Œå›å‚³ {len(df)} ç­†è³‡æ–™")
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è©¢åŸ·è¡Œå¤±æ•—: {e}")
            return pd.DataFrame()
        finally:
            self.disconnect()

    # def get_hourly_listening_data(self, days_back=30):
    #     """ç²å–æ¯å°æ™‚è†è½çµ±è¨ˆè³‡æ–™"""
        
    #     # æœ€ç°¡å–®çš„æŸ¥è©¢ - å…ˆè©¦ raw_staging
    #     query = """
    #     SELECT 
    #         EXTRACT(HOUR FROM played_at) as hour,
    #         EXTRACT(DOW FROM played_at) as day_of_week,
    #         COUNT(*) as listening_count,
    #         SUM(COALESCE(duration_ms, 0)) / 60000.0 as total_minutes
    #     FROM raw_staging.spotify_listening_raw 
    #     WHERE played_at >= CURRENT_DATE - INTERVAL '%s days'
    #     GROUP BY 1, 2
    #     ORDER BY 2, 1
    #     """
        
    #     df = self.execute_query(query, (days_back,))
        
    #     if df.empty:
    #         self.logger.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°è†è½è³‡æ–™ï¼Œå›å‚³æ¨¡æ“¬è³‡æ–™")
    #         return self._generate_mock_hourly_data()
        
    #     # æª¢æŸ¥è³‡æ–™å…§å®¹ï¼ˆèª¿è©¦ç”¨ï¼‰
    #     self.logger.info(f"æŸ¥è©¢å›å‚³çš„æ¬„ä½: {list(df.columns)}")
    #     if not df.empty:
    #         self.logger.info(f"ç¬¬ä¸€ç­†è³‡æ–™: {df.iloc[0].to_dict()}")
        
    #     # æª¢æŸ¥æ˜¯å¦å›å‚³çš„æ˜¯æ¬„ä½åç¨±è€Œéæ•¸æ“š
    #     if 'hour' in df.values or df.iloc[0]['hour'] == 'hour':
    #         self.logger.warning("âš ï¸ æŸ¥è©¢å›å‚³æ¬„ä½åç¨±ï¼Œä½¿ç”¨æ¨¡æ“¬è³‡æ–™")
    #         return self._generate_mock_hourly_data()
        
    #     try:
    #         # ç¢ºä¿è³‡æ–™é¡å‹æ­£ç¢º
    #         df['hour'] = pd.to_numeric(df['hour'], errors='coerce').astype(int)
    #         df['day_of_week'] = pd.to_numeric(df['day_of_week'], errors='coerce').astype(int)
    #         df['listening_count'] = pd.to_numeric(df['listening_count'], errors='coerce').astype(int)
    #         df['total_minutes'] = pd.to_numeric(df['total_minutes'], errors='coerce').astype(float)
            
    #         # ç§»é™¤ä»»ä½•ç„¡æ•ˆè³‡æ–™
    #         df = df.dropna()
            
    #         if df.empty:
    #             self.logger.warning("âš ï¸ è³‡æ–™è½‰æ›å¾Œç‚ºç©ºï¼Œä½¿ç”¨æ¨¡æ“¬è³‡æ–™")
    #             return self._generate_mock_hourly_data()
                
    #     except Exception as e:
    #         self.logger.error(f"âŒ è³‡æ–™é¡å‹è½‰æ›å¤±æ•—: {e}")
    #         return self._generate_mock_hourly_data()
        
    #     return df
    
    # def get_recent_stats(self, days=7):
    #     """ç²å–æœ€è¿‘å¹¾å¤©çš„è†è½çµ±è¨ˆ"""
        
    #     query = """
    #     SELECT 
    #         COUNT(*) as total_tracks,
    #         COUNT(DISTINCT track_id) as unique_tracks,
    #         COUNT(DISTINCT artist_name) as unique_artists,
    #         AVG(EXTRACT(HOUR FROM played_at)) as avg_hour
    #     FROM raw_staging.spotify_listening_raw 
    #     WHERE played_at >= CURRENT_DATE - INTERVAL '%s days'
    #     """
        
    #     df = self.execute_query(query, (days,))
        
    #     if df.empty or df.iloc[0]['total_tracks'] == 0:
    #         return {
    #             'total_tracks': 156,
    #             'unique_tracks': 89,
    #             'unique_artists': 34,
    #             'avg_hour': 15.3,
    #             'is_mock_data': True
    #         }
        
    #     # æª¢æŸ¥æ˜¯å¦å›å‚³çš„æ˜¯æ¬„ä½åç¨±
    #     if df.iloc[0]['total_tracks'] == 'total_tracks':
    #         self.logger.warning("âš ï¸ çµ±è¨ˆæŸ¥è©¢å›å‚³æ¬„ä½åç¨±ï¼Œä½¿ç”¨æ¨¡æ“¬è³‡æ–™")
    #         return {
    #             'total_tracks': 156,
    #             'unique_tracks': 89,
    #             'unique_artists': 34,
    #             'avg_hour': 15.3,
    #             'is_mock_data': True
    #         }
        
    #     stats = df.iloc[0].to_dict()
        
    #     try:
    #         stats['total_tracks'] = int(pd.to_numeric(stats['total_tracks'], errors='coerce') or 0)
    #         stats['unique_tracks'] = int(pd.to_numeric(stats['unique_tracks'], errors='coerce') or 0)
    #         stats['unique_artists'] = int(pd.to_numeric(stats['unique_artists'], errors='coerce') or 0)
    #         stats['avg_hour'] = float(pd.to_numeric(stats['avg_hour'], errors='coerce') or 12.0)
    #         stats['is_mock_data'] = False
    #     except Exception as e:
    #         self.logger.error(f"âŒ çµ±è¨ˆè³‡æ–™è½‰æ›å¤±æ•—: {e}")
    #         return {
    #             'total_tracks': 156,
    #             'unique_tracks': 89,
    #             'unique_artists': 34,
    #             'avg_hour': 15.3,
    #             'is_mock_data': True
    #         }
        
    #     return stats
    
    # def _generate_mock_hourly_data(self):
    #     """ç”Ÿæˆæ¨¡æ“¬è³‡æ–™"""
    #     np.random.seed(42)
    #     data = []
        
    #     for day in range(7):
    #         for hour in range(24):
    #             if day in [0, 6]:  # é€±æœ«
    #                 base_prob = 0.7
    #             else:  # å¹³æ—¥
    #                 base_prob = 0.5
                
    #             if 6 <= hour <= 9:
    #                 time_multiplier = 0.8
    #             elif 10 <= hour <= 17:
    #                 time_multiplier = 1.2
    #             elif 18 <= hour <= 23:
    #                 time_multiplier = 1.8
    #             else:
    #                 time_multiplier = 0.3
                
    #             prob = base_prob * time_multiplier
    #             listening_count = int(np.random.poisson(prob * 10))
    #             total_minutes = listening_count * 3.5
                
    #             data.append({
    #                 'hour': hour,
    #                 'day_of_week': day,
    #                 'listening_count': listening_count,
    #                 'total_minutes': total_minutes
    #             })
        
    #     return pd.DataFrame(data)

# æ¸¬è©¦åŠŸèƒ½
# if __name__ == "__main__":
#     db = SupabaseManager()
    
#     # æ¸¬è©¦é€£ç·š
#     if db.test_connection():
#         print("è³‡æ–™åº«é€£ç·šæˆåŠŸï¼")
        
#         # æ¸¬è©¦è³‡æ–™ç²å–
#         query = """
#             select track_name, COUNT(track_name) as Freq
#             from dwh.fact_listening as f
#             left join dwh.dim_tracks as t
#             on f.track_key = t.track_key
#             -- where f.played_at > "20251025"
#             group by track_name
#             order by COUNT(track_name) desc
#             """
#         df = db.execute_query(query)
#         print("æŸ¥è©¢çµæœï¼š")
#         print(df)
        
#     else:
#         print("è³‡æ–™åº«é€£ç·šå¤±æ•—")